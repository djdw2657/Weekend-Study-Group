{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "통계학4장.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ2DJjErcs-F"
      },
      "source": [
        "4.1 통계모델\n",
        "\n",
        "이 절에서는 통계모델의 기본이론을 설명하겠습니다. 통계모델이란 무엇인가, 데이터분석을 할 때 통계모델이 왜 필요한지 배웁니다.\n",
        "\n",
        "4.1.1 모델\n",
        "\n",
        "여기서 애기하는 모델은 프라모델의 모델, 즉 모형이라고 번역할 수 있습니다. 단순히 모델이라고 말할 경우 현실 세계의 모형이라고 해석할 수 있습니다.\n",
        "\n",
        "4.1.2 모델링\n",
        "\n",
        "모델을 만드는 것을 모델링이라고 합니다. 통계모델을 만드는 것을 통계모델링이라고 합니다.\n",
        "\n",
        "4.1.3 모델은 무엇에 도움이 되나\n",
        "\n",
        "비행기의 형태를 한 작은 모형을 만들면 진짜 비행기를 사용하지 않고도 진짜 비행기의 특성을 들어 그 비행기가 날 수 있는지, 바람이 불면 어떻게 흔들리는지 등을 알아볼 수 있습니다. 실세계의 모형(모델)을 이용하는 것으로 현실 세계의 이핻와 예측에 활용할 수 있습니다.\n",
        "\n",
        "4.1.4 복잡한 세계를 단순화하다\n",
        "\n",
        "예를 들어 맥주 매상 데이터 모델화를 시도해보았다고 합시다. 맥주 매상은 그날의 기온이나 습도, 프로야구팀의 승패, 경제 상황, 맥주를 좋아하는 사람의 많고 적음, 맥주에 잘 어울리는 안주에 쓰이는 재료의 어획량을 결정하는 바닷물의 수온을 좌우하는 1년 3개월 전의 쿠로시오 해류 등 무수한 요인에 의해 변화할 것입니다. 하지만 그런 요인들을 모두 고려하는 것은 비효율적입니다. 모든 요인을 계산에 집어넣으면 인간은 이해할 수 없는 수수께끼 같은 인과율이 튀어나올 것입니다. 쿠로시오 해류의 흐름이 바뀌면 1년 3개월 후의 맥주 매상이 평균 50엔 늘어난다는 것에서는 가치를 찾기 어려울 것입니다.\n",
        "\n",
        "여러 가지 요소들을 과감히 무시하고, 맥주 매상은 기온이 올라가면 늘어난다는 측면만 주목하는 쪽이 간단합니다. 더우면 맥주를 마시고 싶어진다고 하면 이해하기 쉽지만, 너무 단순하게만 하면 현실과 맞지 않는 모델이 될 수도 있습니다. 인간이 이해할 수 있을 만큼 단순하고 그러면서도 복잡한 현실상을 어느 정도 잘 설명할 수 있는 복잡한 세계를 위한 단순한 모델을 구축하세요.\n",
        "\n",
        "4.1.5 복잡한 현상을 특정한 관점에서 다시 보게 한다.\n",
        "\n",
        "모델은 실제 현상을 어떤 측면에서 바라본 결과라고 애기할 수도 있습니다. 기온과 맥주매상 관계라는 '그날의 기온이라는 관점'에서 바라본 모델 구축을 생각해 볼 수 있습니다. 맥주를 자주 마시는 인구수와 맥주 매상이라는 장기적 소비자수 추이에 따른 관점에서 바라본 모델을 구축하는 것 또한 생각해볼 수 있습니다. 어느 쪽이 올바르다고 말하려는 것이 아닙니다. 분석의 목적에 맞춰서 작성하는 모델과 주목하는 관점을 바꾸는 것이 가능하다는 애기입니다.\n",
        "\n",
        "4.1.6 수리모델\n",
        "\n",
        "수리모델은 현상을 수식으로 표현한 모델을 말합니다.\n",
        "\n",
        "'맥주 매상은 기온에 의해 변한다'라는 모델을 가정해보겠습니다. 말만으로는 기온이 오르면 \n",
        "맥주매상(만원) = 20 +4 * 기온(C)\n",
        "\n",
        "기온이 1C 오르면 맥주 매상이 4만원 늘어납니다. 기온이 0C 일때 맥주 매상은 20만원입니다. 기온이 20C 라면 맥주 매상은 20+80 = 100만원입니다.\n",
        "\n",
        "이와 같이 수식으로 표현하면 맥주와 기온의 관계가 보다 명확해집니다.\n",
        "\n",
        "4.1.7 확률모델\n",
        "\n",
        "수리모델 중에서도 특히 확률적인 표현이 있는 모델을 확률모델이라고 합니다.\n",
        "\n",
        "기온이 20C 라고 했을 때 맥주 매상이 딱 100만원이 되는 일은 현실에서는 잘 없을 것입니다. 기온이 20C이더라도 맥주가 많이 팔리는 날도 있을 것이고, 많이 팔리지 않는 날도 있을 것이지만 평균은 약 100만원이 될 것입니다. 이런 식으로 생각하는 경우에는 확률모델을 사용합니다.\n",
        "\n",
        "확률적인 표현을 하기 위해서는 확률분포를 사용합니다. 확률분포로는 정규분포 등이 사용됩니다. (물론 데이터에 따라 정규분포 이외의 분포가 사용되는 경우도 있습니다. 일반선형모델에서는 푸아송 분포나 이항분포 등이 사용됩니다.)\n",
        "\n",
        "예를 들어, 정규분포를 가정했을 때의 맥주 매상을 기온으로 설명하는 확률모델이 아래와 같다고 합시다.\n",
        "\n",
        "맥주 매상 ~N(20+4*기온)\n",
        "\n",
        "이는 '맥주 매상은 평균이 20+4* 기온이고, 분산이 정규분포'를 따른다는 생각을 표현한 것입니다. \n",
        "\n",
        "[식4-2]는 아래와 같이 쓸 수도 있습니다.\n",
        "\n",
        "맥주 매상 = 20+4*기온+e e~N(O,@^2)\n",
        "\n",
        "4.2.5 선형모델\n",
        "\n",
        "선형모델은 종속변수화 독립변수의 관계를 선형으로 보는 모델입니다.\n",
        "\n",
        "4.2.6 계수와 가중치\n",
        "\n",
        "통계모델에 사용되는 파라미터를 계수라고 합니다.\n",
        "\n",
        "맥주매상 ~ N(B0+B1*기온, a^2)\n",
        "B0,B1이 계수 \n",
        "이러한 계수와 독립변수(기온)이 있으면 모수를 추측할 수 있음\n",
        "B0 절편, B1 회귀계수(머신러닝에서 가중치라고 표현)\n",
        "\n",
        "4.2.7 모델 구축 = 모델 정하기 + 파라미터 추정\n",
        "\n",
        "4.2.8 선형모델을 구축하는 방법\n",
        "\n",
        "선형모델임을 가정했을 때 모델의 구조를 바꾸는 방법은 대부분 아래 두 가지입니다.\n",
        "모델에 사용되는 독립변수를 바꾼다.\n",
        "데이터가 따르는 확률분포를 바꾼다.\n",
        "\n",
        "4.2.9 변수 선택\n",
        "\n",
        "4.2.11 검정을 이용한 변수 선택\n",
        "\n",
        "귀무가설 : 독립변수의 계수 B1은 0이다\n",
        "대립가설 : 독립변수 계수 B1은 0이 아니다\n",
        "\n",
        "4.2.12 정보 기준을 이요한 변수 선택\n",
        "\n",
        "정보 기준이란 추정한 모델의 좋은 정도를 정량화한 지표\n",
        "\n",
        "4.2.13 모델 평가\n",
        "1. 예측 정확도의 평가\n",
        "\n",
        "4.2.14 통계모델을 만들기 전에 분석의 목적을 정한다.\n",
        "\n",
        "분석의 목적을 결정하고 데이터를 수집하여 모델링하는 것이 중요\n",
        "\n",
        "4.3 데이터의 표현과 모델의 명칭\n",
        "\n",
        "4.3.1 정규선형모델\n",
        "\n",
        "종속변수가 정규분포를 따르는 것을 가정한 선형모델을 정규선형모델이라고 합니다. 종속변수가 정규분포를 따른다고 가정하기 때문에 종속변수는 연속형 변수가 됩니다.\n",
        "\n",
        "4.3.2 회귀분석\n",
        "정규선형모델 중 독립변수가 연속형 변수인 모델을 회귀분석이라고 합니다. \n",
        "\n",
        "4.3.3 다중회귀분석\n",
        "회귀분석 중에서도 독립변수가 여러 개 있는 것을 다중회귀분석이라고 합니다. \n",
        "\n",
        "4.3.4 분산분석\n",
        "\n",
        "정규선형모델 중에서 독립변수가 카테고리형 변수인 모델을 분산분석 모델이라고 합니다.\n",
        "\n",
        "독립변수가 1종류일 때 일원분산분석 2종류일때 이원분석분삭이라고 합니다. \n",
        "\n",
        "4.3.5 일반성형모델\n",
        "종속변수가 따르는 확률분포 이외의 분포에도 사용가능하게 한 선형모델\n",
        "\n",
        "4.3.6 머신러닝에서의 며잋ㅇ\n",
        "머신러닝 분야의 회귀는 종속변수가 연속형 변수인 모델을 의미함 \n",
        "\n",
        "4.4 파라미터 추정 : 우도의 최대화\n",
        "\n",
        "4.4.1 파라미터 추정 방법을 배우는 의미\n",
        "파라미터 추정을 알면 계산을 실행하면서 에러나 경고가 나왔을 때 원인을 찾을 수 있음\n",
        "\n",
        "4.4.2 우도\n",
        "표본을 얻을 수 있는 확률(밀도)을 우도라고 합니다.\n",
        "우도 : 그럴듯한 정도라는 뜻\n",
        "\n",
        "확률이 1/2인 동전 1/2이 파라미터임\n",
        "\n",
        "앞면이 나올 확률 1/3인 경우 우도는 1/3 * 2/3 = 2/9가 됨\n",
        "\n",
        "4.4.3 우도함수\n",
        "\n",
        "파라미터를 넘겨서 우도를 계산할 수 있는 함수\n",
        "\n",
        "L(@) = @*(1-@)\n",
        "\n",
        "4.4.4 로그우도\n",
        "\n",
        "우도에 로그를 취한 것을 로그우도라고 합니다.\n",
        "\n",
        "4.4.5 로그의 성질\n",
        "\n",
        "지수 : 2에 3승\n",
        "로그 : 로그는 X의 Y승 =Z의 관계에서 X와Z를 고정해서 Y를 구하는 계산을 말합니다.\n",
        "\n",
        "log(2)8 = 3\n",
        "\n",
        "2는 로그의 밑이라고 부름\n",
        "자연로그 3는 약 2.7인데 계산이 간단해지기 떄문에 자주 사용\n",
        "\n",
        "성질1:단조증가한다\n",
        "f(x)=log x 가 있을 때 x가 커질수록 log x 의 값도 커짐 이러한 성질이 있어서 우도를 최대로 하는 파라미터를 찾을 결과는 로그우도를 최대로 하는 파라미터를 찾은 결과와 일치하게 됩니다.\n",
        "\n",
        "성질2:곱셈이 덧셈으로 바뀐다.\n",
        "로그를 취하면 곱셈이 덧셈으로 바뀌게 됩니다.\n",
        "\n",
        "\n",
        "log2(2*4) = log2 8\n",
        "\n",
        "log(xy) = logx+logy\n",
        "\n",
        "성질3 : 절댓값이 극단적으로 작은 값이 되기 어렵다.\n",
        "\n",
        "로그를 취하면 극단적으로 작은 값이 되기 어렵다는 장점\n",
        "\n",
        "log2 (1/1024) = -10\n",
        "\n",
        "4.4.6 최대우도범\n",
        "\n",
        "최대우도법은 우도나 로그우도의 결과를 최대로 하기 위한 파라미터 추정시 사용하는 방법\n",
        "\n",
        "동전던지기시  최대우도법 사용하면 파라미터 @ =1/2로 추정함\n",
        "\n",
        "파라미터 @ 1/2 우도 1/4\n",
        "파라미터 @ 1/3 우도 2/9 \n",
        "\n",
        "4.4.7 최대우도 추정량\n",
        "\n",
        "최대우도법에 의해 추정된 파라미터를 최대우도추정량이라 하며 ^@로 표시\n",
        "\n",
        "4.4.8 최대화 로그우도\n",
        "\n",
        "logL(^@)를 최대화 로그우도라 함\n",
        "\n",
        "4.4.9 정규분포를 따르는 데이터의 우도\n",
        "\n",
        "y~N(u,@^2)\n",
        "\n",
        "y1을 얻었을 때의 확률 밀도는 N(y1|u,@^2)\n",
        "\n",
        "4.4.10 장애모수\n",
        "\n",
        "직접적인 관심의 대상이 아닌 파라미터를 장애모수라고 합니다.\n",
        "\n",
        "모수는 평균과 분산 2가지입니다.\n",
        "\n",
        "4.4.11 정규선형모델의 우도\n",
        "\n",
        "맥주매상 ~ N(B0+B1*기온, @2)\n",
        "\n",
        "우도는 아래와 같이 계싼할 수 있음 @2는 장애모수\n",
        "\n",
        "L = N(Y1|B0+B1X1, @2) * N(Y2|B0+B1X2, @2)\n",
        "\n",
        "4.4.12 최대우도법 계산 예\n",
        "\n",
        "4.4.13 최대우도추정량의 성질\n",
        "최대우도추정량은 샘플사이즈가 커질때 추정량의 표본분포가 점근적으로 정규분포를 따른다고 알려짐\n",
        "\n",
        "표본분산의 분산이 작다는 것은 추정치의 흩어짐이 작고, 추정의 오차가 작다는 의미이므로 최대우도추정량은 바람직한 성질을 가진 추정량이라고 할 수 있습니다.\n",
        "\n",
        "4.5.1 손실함수\n",
        "\n",
        "손실함수는 파라미터 추정을 할때 손실을 최소화하는 목적으로 사용됨\n",
        "\n",
        "4.5.2 잔차\n",
        "\n",
        "실제 종속 변수의 값과 모델을 이용해서 계산한 종속변수의 추정치와의 차이를 잔차라고 부릅니다. 아래의 맥주 매상 모델을 예로 들어보겠습니다.\n",
        "\n",
        "residuals = y(종속변수,맥주매상) - y^(추정치)\n",
        "\n",
        "4.5.3 잔차의 합을 그대로 손실의 지표로 사용할 수 없는 이유\n",
        "잔차의 합이 0이 되므로 차이를 알 수 없음\n",
        "\n",
        "4.5.4 잔차제곱합\n",
        "\n",
        "잔차를 제곱해서 합계를 구한 것을 잔차제곱합이라고 합니다. 잔차제곱합을 사용하면 잔차의 합이 가지는 문제를 해결할 수 있습니다.\n",
        "\n",
        "샘플사이즈가 N인 표본의 잔차제곱합은 아래와 같이 표기합니다.\n",
        "\n",
        "4.5.5 최소제곱법\n",
        "\n",
        "잔차제곱합을 최소로 하는 파라미터를 채용하는 방법을 최소제곱법이라고 합니다. \n",
        "\n",
        "4.5.6 최소제곱법과 최대우도법의 관계\n",
        "\n",
        "최소제곱법을 이용한 파라미터 추정치는 모집단분포가 정규분포임을 가정했을 때의 최대우도법의 결과와 일치합니다.\n",
        "\n",
        "4.5.7 오차함수\n",
        "\n",
        "머신러닝 분야에서 로그우도의 부호를 바꾼 것을 오차함수라고 부릅니다. 최소제곱법은 모집단분포가 정규분포임을 가정했을 떄의 오차함수를 최소화하는 것이라고 해석할 수 있습니다.\n",
        "\n",
        "4.5.8 여러 가지 손실함수\n",
        "\n",
        "잔차제곱합을 손실로 정의한 정규선형모델에서는 잔차제곱법으로 최대우도법을 이용한 추정치와 같은 파라미터를 추정할 수 있다는 것을 알았습니다.\n",
        "\n",
        "4.6 예측정확도의 평가와 변수 선택\n",
        "\n",
        "\n",
        "4.6.1 적합도와 예측 정확도\n",
        "\n",
        "적합도는 가지고 있는 데이터에 대해 모델을 적용했을 때 들어맞는 정도\n",
        "\n",
        "예측 정확도는 아직 얻지 못한 데이터에 대해 모델을 적용했을 떄 맞는 정도\n",
        "\n",
        "4.6.2 과적합(오버피팅)\n",
        "적합도는 높은데, 예측 정확도가 낮아지는 경우 과적합이라고 합니다.\n",
        "\n",
        "4.6.3 변수 선택의 의의\n",
        "필요 없는 독립변수를 제외하는 것만으로도 예측 정확도가 높아질 가능성이 있음\n",
        "\n",
        "4.6.4 일반화 오차\n",
        "\n",
        "아직 얻지 못한 데이터에 대한 예측오차를 일반화 오차라고 합니다.\n",
        "\n",
        "4.6.5 훈련 데이터와 테스트 데이터\n",
        "\n",
        "훈련 데이터(트레이닝 데이터)는 파라미터 추정에 사용되는 데이터입니다. 훈련 데이터의 적합도를 평가하는 것으로 모델의 정확도는 구할 수 있지만 일반화 오차를 평가하는 건 어렵습니다.\n",
        "\n",
        "테스트 데이터는 일반화 오차를 평가하기 위해 파라미터 추정을 할때 사용하지 않고 남겨둔 데이터임\n",
        "\n",
        "4.6.6 교차검증\n",
        "\n",
        "교차검증은 데이터를 일정한 규칙에 따라 훈련 데이터와 테스트 데이터로 나누어 예측 정확도를 평가하는 방법\n",
        "\n",
        "리브-p-이웃 교차검증 : p개의 데이터를 추출하고 남은 데이터를 테스트 데이터로 사용\n",
        "\n",
        "k겹 교차검증 : 가지고 있는 데이터를 k개의 그룹으로 나눔. 그 그룹 중에서 하나를 추출하여 테스트 데이터로 사용하고, k번 반복하여 예측 정확도의 평균값을 평가값으로 사용\n",
        "\n",
        "교차검증은 몇번이고 파라미터 추정 ~ 정확도 평가를 반복하기 때문에 계산량이 많아지는 단점이 있음\n",
        "\n",
        "4.6.7 아카이케 정보 기준\n",
        "\n",
        "AIC = -2*(최대로그우도-추정된 파라미터 수)\n",
        "작을 수록 좋은 모델\n",
        "\n",
        "로그우도가 크면 적합도가 높아짐. 적합도를 높게 하는데 주력하면 일반화 오차 커짐. 때문에 AIC로 추정한 파라미터 수를 적합도에 대한 페널티로 사용. 독립변수가 많아지면 로그우도가 커지면 페널티도 커짐. AIC는 페널티를 보강하고 지나치게 로그우도가 높아지는지 판단하는 지표로 볼 수 있음\n",
        "\n",
        "4.6.8 상대 엔트로피\n",
        "\n",
        "확률분포의 차이를 측정하는 지표가 상대 엔트로피\n",
        "\n",
        "상대 엔트로피 : f g(x){log g(x) - log f(x)}dx\n",
        "x의 기댓값 : f f(x)*xdx\n",
        "\n",
        "4.6.9 상대 엔트로피의 최소화와 평균로그우도\n",
        "\n",
        "fg(y){logg(y)-logf(y)}dy\n",
        "\n",
        "4.6.10 평균로그우도가 지니는 편향과 AIC\n",
        "\n",
        "평균로그우도 자체를 계산하는 것은 어렵기 때문에 최대로그우도를 대신 사용합니다. 이 편향의 크기는 추정된 파라미터 수라는 것이 수학적으로 증명되어 있습니다. 때문에 이 편향을 없앤 것이 AIC가 되어 아래와 같이 계산합니다.\n",
        "\n",
        "AIC = -2 * (최대로그우도 - 추정된 파라미터 수)\n",
        "\n",
        "그 뒤는 그냥 읽기만 함\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP5S5yBWc07x"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49oKWyKqcyQe"
      },
      "source": [
        ""
      ]
    }
  ]
}